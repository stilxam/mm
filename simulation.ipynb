{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-19T12:40:43.589444185Z",
     "start_time": "2024-10-19T12:40:42.381058263Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from typing import Tuple, List, Dict, Any\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df =  pd.read_csv(\"data/japan_n_skorea.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-19T12:40:43.590277502Z",
     "start_time": "2024-10-19T12:40:43.322908935Z"
    }
   },
   "id": "944dfd4c3e9da4a5"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "def time_difference(time: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Calculate the time difference between the current time and the next time.\n",
    "    \n",
    "    :param time: A pandas Series of datetime values.\n",
    "    :return: A pandas Series of time differences.\n",
    "    \"\"\"\n",
    "    time_diff = time - time.shift(1)\n",
    "    return time_diff\n",
    "\n",
    "def process_time(time: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Process the time series data by converting to datetime, sorting, and calculating time differences.\n",
    "    \n",
    "    :param time: A pandas Series of datetime values.\n",
    "    :return: A pandas Series of time differences in seconds.\n",
    "    \"\"\"\n",
    "    time = pd.to_datetime(time)\n",
    "    time = time.sort_values()\n",
    "    dt = time_difference(time)\n",
    "    dt = dt.dt.total_seconds()\n",
    "    dt = dt[dt > 0].reset_index(drop=True)\n",
    "    return dt\n",
    "\n",
    "\n",
    "def analyze_distributions(in_series: pd.Series, significance: float = 0.05) -> Tuple[List[List[Any]], Dict[str, Dict[str, float]]]:\n",
    "    \"\"\"\n",
    "    Analyze the distribution of the data and test for goodness of fit.\n",
    "    \n",
    "    :param in_series: A pandas Series of time differences.\n",
    "    :param significance: Significance level for the goodness of fit tests.\n",
    "    :return: A tuple containing the results of the analysis and the output parameters.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    output_parameters = {}\n",
    "\n",
    "    # Uniform distribution\n",
    "    fit_uniform_dist = stats.uniform(loc=(in_series.min()), scale=in_series.max() - in_series.min())\n",
    "    test = stats.kstest(in_series, fit_uniform_dist.cdf)\n",
    "    p_value = test[1]\n",
    "    fit_status = \"Good fit\" if p_value > significance else \"Bad fit\"\n",
    "    results.append([\"Uniform Distribution\", fit_status, p_value])\n",
    "    output_parameters[\"Uniform Distribution\"] = {\n",
    "        \"loc\": in_series.min(),\n",
    "        \"scale\": in_series.max() - in_series.min()\n",
    "    }\n",
    "\n",
    "    # Exponential distribution\n",
    "    m1 = np.mean(in_series)\n",
    "    fit_exponential_dist = stats.expon(scale=1 / m1)\n",
    "    test = stats.kstest(in_series, fit_exponential_dist.cdf)\n",
    "    p_value = test[1]\n",
    "    fit_status = \"Good fit\" if p_value > significance else \"Bad fit\"\n",
    "    results.append([\"Exponential Distribution\", fit_status, p_value])\n",
    "    output_parameters[\"Exponential Distribution\"] = {\n",
    "        \"estimated_lambda\": 1 / m1\n",
    "    }\n",
    "\n",
    "    # Gamma distribution\n",
    "    m2 = np.mean([x ** 2 for x in in_series])\n",
    "    est_beta = m1 / (m2 - m1 ** 2)\n",
    "    est_alpha = m1 * est_beta\n",
    "    fit_gamma_dist = stats.gamma(a=est_alpha, scale=1 / est_beta)\n",
    "    test = stats.kstest(in_series, fit_gamma_dist.cdf)\n",
    "    p_value = test[1]\n",
    "    fit_status = \"Good fit\" if p_value > significance else \"Bad fit\"\n",
    "    results.append([\"Gamma Distribution\", fit_status, p_value])\n",
    "    output_parameters[\"Gamma Distribution\"] = {\n",
    "        \"estimated_alpha\": est_alpha,\n",
    "        \"estimated_beta\": est_beta\n",
    "    }\n",
    "\n",
    "    # Poisson distribution\n",
    "    fi_poisson_dist = stats.poisson(mu=m1)\n",
    "    test = stats.kstest(in_series, fi_poisson_dist.cdf)\n",
    "    p_value = test[1]\n",
    "    fit_status = \"Good fit\" if p_value > significance else \"Bad fit\"\n",
    "    results.append([\"Poisson Distribution\", fit_status, p_value])\n",
    "    output_parameters[\"Poisson Distribution\"] = {\n",
    "        \"estimated_lambda\": m1\n",
    "    }\n",
    "\n",
    "    # Normal distribution\n",
    "    estimated_std = m2 - m1 ** 2\n",
    "    fit_normal_dist = stats.norm(loc=m1, scale=estimated_std)\n",
    "    test = stats.kstest(in_series, fit_normal_dist.cdf)\n",
    "    p_value = test[1]\n",
    "    fit_status = \"Good fit\" if p_value > significance else \"Bad fit\"\n",
    "    results.append([\"Normal Distribution\", fit_status, np.format_float_scientific(test[1], precision=2)])\n",
    "    output_parameters[\"Normal Distribution\"] = {\n",
    "        \"estimated_mean\": m1,\n",
    "        \"estimated_std\": estimated_std\n",
    "    }\n",
    "    return results, output_parameters\n",
    "\n",
    "\n",
    "def main(data:pd.DataFrame, case:str) -> Tuple[List[List[Any]], Dict[str, Dict[str, float]]]:\n",
    "    \"\"\"\n",
    "    Main function to process time series data, analyze distributions, and plot the results.\n",
    "    \n",
    "    :return: A tuple containing the results of the analysis and the output parameters.\n",
    "    \"\"\"\n",
    "    cases = [\"All\", \"Large\", \"Small\"]\n",
    "    assert case in cases, f\"Invalid case. Choose from {cases}\"\n",
    "    \n",
    "    time = None\n",
    "    \n",
    "    if case == \"All\":\n",
    "        time = data[\"time\"]\n",
    "    elif case == \"Large\":\n",
    "        time = data[data[\"mag\"] > 5][\"time\"]\n",
    "    elif case == \"Small\":\n",
    "        time = data[data[\"mag\"] < 5][\"time\"]\n",
    "        \n",
    "\n",
    "    dt = process_time(time)\n",
    "    results, output_parameters = analyze_distributions(dt)\n",
    "    return results, output_parameters\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-19T12:40:43.590583227Z",
     "start_time": "2024-10-19T12:40:43.323414488Z"
    }
   },
   "id": "8a6e368d8f799b58"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "results, output_parameters = main(df, \"All\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-19T12:40:43.590821570Z",
     "start_time": "2024-10-19T12:40:43.323970255Z"
    }
   },
   "id": "68c6402032745c62"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def find_max_fit(results: List[List[Any]]) -> List[Any]:\n",
    "    \"\"\"\n",
    "    Find the distribution with the maximum goodness of fit.\n",
    "    \n",
    "    :param results: A list containing the results of the analysis.\n",
    "    :return: A list containing the distribution with the maximum goodness of fit.\n",
    "    \"\"\"\n",
    "    max_fit = max([x[2] for x in results])\n",
    "    return [x for x in results if x[2] == max_fit][0]\n",
    "\n",
    "\n",
    "def generate_distribution(dist, output_parameters: Dict[str, Dict[str, float]], n) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a pandas DataFrame containing the distribution parameters.\n",
    "    \n",
    "    :param dist: A string representing the distribution name.\n",
    "    :param output_parameters: A dictionary containing the output parameters.\n",
    "    :return: A pandas DataFrame containing the distribution parameters.\n",
    "    \"\"\"\n",
    "    if dist == \"Uniform Distribution\":\n",
    "        loc = output_parameters[dist][\"loc\"]\n",
    "        scale = output_parameters[dist][\"scale\"]\n",
    "        data = stats.uniform.rvs(loc=loc, scale=scale, size=n)\n",
    "    elif dist == \"Exponential Distribution\":\n",
    "        estimated_lambda = output_parameters[dist][\"estimated_lambda\"]\n",
    "        data = stats.expon.rvs(scale=1 / estimated_lambda, size=n)\n",
    "    elif dist == \"Gamma Distribution\":\n",
    "        estimated_alpha = output_parameters[dist][\"estimated_alpha\"]\n",
    "        estimated_beta = output_parameters[dist][\"estimated_beta\"]\n",
    "        data = stats.gamma.rvs(a=estimated_alpha, scale=1 / estimated_beta, size=n)\n",
    "    elif dist == \"Poisson Distribution\":\n",
    "        estimated_lambda = output_parameters[dist][\"estimated_lambda\"]\n",
    "        data = stats.poisson.rvs(mu=estimated_lambda, size=n)\n",
    "    elif dist == \"Normal Distribution\":\n",
    "        estimated_mean = output_parameters[dist][\"estimated_mean\"]\n",
    "        estimated_std = output_parameters[dist][\"estimated_std\"]\n",
    "        data = stats.norm.rvs(loc=estimated_mean, scale=estimated_std, size=n)\n",
    "    return pd.DataFrame(data, columns=[\"data\"])\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-19T12:40:43.591071785Z",
     "start_time": "2024-10-19T12:40:43.375850931Z"
    }
   },
   "id": "4022ee219e521c36"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Uniform Distribution': {'loc': np.float64(7.42),\n  'scale': np.float64(3999488.52)},\n 'Exponential Distribution': {'estimated_lambda': np.float64(5.917803647212268e-06)},\n 'Gamma Distribution': {'estimated_alpha': np.float64(0.49280378256898094),\n  'estimated_beta': np.float64(2.916316021846717e-06)},\n 'Poisson Distribution': {'estimated_lambda': np.float64(168981.6120328824)},\n 'Normal Distribution': {'estimated_mean': np.float64(168981.6120328824),\n  'estimated_std': np.float64(57943518729.45413)}}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parameters"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-19T12:40:43.837169458Z",
     "start_time": "2024-10-19T12:40:43.379311131Z"
    }
   },
   "id": "f426428cbc4592ea"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-19T12:40:43.837625223Z",
     "start_time": "2024-10-19T12:40:43.400116308Z"
    }
   },
   "id": "fa85c6441759fd98"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-19T12:40:43.838007358Z",
     "start_time": "2024-10-19T12:40:43.403205493Z"
    }
   },
   "id": "c1e6946aa1a3122a"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-19T12:40:43.838259780Z",
     "start_time": "2024-10-19T12:40:43.444847137Z"
    }
   },
   "id": "89ac097fe6bf85d9"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-19T12:40:43.838492759Z",
     "start_time": "2024-10-19T12:40:43.445166289Z"
    }
   },
   "id": "a873c5fc9344a797"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-19T12:40:43.838732763Z",
     "start_time": "2024-10-19T12:40:43.445428446Z"
    }
   },
   "id": "aba0fbb153d0c2e"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-19T12:40:43.838985580Z",
     "start_time": "2024-10-19T12:40:43.445653403Z"
    }
   },
   "id": "64a0508fa2f904a1"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-19T12:40:43.839215870Z",
     "start_time": "2024-10-19T12:40:43.445888392Z"
    }
   },
   "id": "b70cbc30a873f7ce"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-19T12:40:43.839615379Z",
     "start_time": "2024-10-19T12:40:43.446091137Z"
    }
   },
   "id": "5b93629ef48b9b30"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-19T12:40:43.839873255Z",
     "start_time": "2024-10-19T12:40:43.446943916Z"
    }
   },
   "id": "59a0370b91424518"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-19T12:40:43.840141270Z",
     "start_time": "2024-10-19T12:40:43.447133270Z"
    }
   },
   "id": "6875a204ca70ee7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4d357308b9c03c7b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
